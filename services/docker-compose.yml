version: '3'
services:
  namenode:
    image: registry.gitlab.com/rychly-edu/docker/docker-hdfs:3.2.1
    environment:
      - ROLE=namenode
      - DFS_DEFAULT=hdfs://namenode:8020
      - NAME_DIRS=/home/hadoop/name
      - DFS_NAMENODES=rpc://namenode:8020,http://namenode:9870,https://namenode:9871
      - ADD_USERS=spark
      - PROP_HDFS_dfs_permissions_enabled=false
    ports:
      - "54987:9870"
      - "54988:8020"
    volumes:
#      - .\volumes\namenode:/home/hadoop/name   # For Windows systems
      - ./volumes/namenode:/home/hadoop/name    # For UNIX systems

  datanode1:
    image: registry.gitlab.com/rychly-edu/docker/docker-hdfs:3.2.1
    environment:
      - ROLE=datanode
      - DFS_DEFAULT=hdfs://namenode:8020
      - DATA_DIRS=/home/hadoop/data
      - DFS_DATANODES=data://0.0.0.0:9866,http://0.0.0.0:9864,https://0.0.0.0:9865,ipc://0.0.0.0:9867
      - PROP_HDFS_dfs_permissions_enabled=false
#    ports:
#      - "9866"
#      - "9864"
#      - "9865"
#      - "9867"
    volumes:
#      - .\volumes\datanode1:/home/hadoop/data  # For Windows systems
      - ./volumes/datanode1:/home/hadoop/data   # For UNIX systems

  datanode2:
    image: registry.gitlab.com/rychly-edu/docker/docker-hdfs:3.2.1
    environment:
      - ROLE=datanode
      - DFS_DEFAULT=hdfs://namenode:8020
      - DATA_DIRS=/home/hadoop/data
      - DFS_DATANODES=data://0.0.0.0:9866,http://0.0.0.0:9864,https://0.0.0.0:9865,ipc://0.0.0.0:9867
      - PROP_HDFS_dfs_permissions_enabled=false
#    ports:
#      - "9866"
#      - "9864"
#      - "9865"
#      - "9867"
    volumes:
#      - .\volumes\datanode2:/home/hadoop/data   # For Windows systems
      - ./volumes/datanode2:/home/hadoop/data   # For UNIX systems


  datanode3:
    image: registry.gitlab.com/rychly-edu/docker/docker-hdfs:3.2.1
    environment:
      - ROLE=datanode
      - DFS_DEFAULT=hdfs://namenode:8020
      - DATA_DIRS=/home/hadoop/data
      - DFS_DATANODES=data://0.0.0.0:9866,http://0.0.0.0:9864,https://0.0.0.0:9865,ipc://0.0.0.0:9867
      - PROP_HDFS_dfs_permissions_enabled=false
#    ports:
#      - "9866"
#      - "9864"
#      - "9865"
#      - "9867"
    volumes:
#      - .\volumes\datanode3:/home/hadoop/data   # For Windows systems
      - ./volumes/datanode3:/home/hadoop/data   # For UNIX systems

  sparkmaster:
#    image: registry.gitlab.com/rychly-edu/docker/docker-spark:2.4.4-hadoop3.2
    image: ghcr.io/miroslavis/spark:1.2
    environment:
      - ROLE=master
      - MASTER_PORT=7077
      - WEBUI_PORT=4040
    ports:
#      - "7077:7077"
      - "54040:4040"

  sparkworker:
    image: ghcr.io/miroslavis/spark:1.2
    # to restart lost workers (i.e., workers exited with after a task or on a failure when asked to kill an executor)
    restart: always
    environment:
      - ROLE=worker
      - MASTER_URL=spark://sparkmaster:7077
      - WEBUI_PORT=4040
      - SPARK_WORKER_CORES=2
      - SPARK_WORKER_MEMORY=1g
    ports:
      - "54041:4040"

  sparkworker2:
    image: ghcr.io/miroslavis/spark:1.2
    restart: always
    environment:
      - ROLE=worker
      - MASTER_URL=spark://sparkmaster:7077
      - WEBUI_PORT=4040
      - SPARK_WORKER_CORES=2
      - SPARK_WORKER_MEMORY=1g
    ports:
      - "54042:4040"

  sparkworker3:
    image: ghcr.io/miroslavis/spark:1.2
    restart: always
    environment:
      - ROLE=worker
      - MASTER_URL=spark://sparkmaster:7077
      - WEBUI_PORT=4040
      - SPARK_WORKER_CORES=2
      - SPARK_WORKER_MEMORY=1g
    ports:
      - "54043:4040"

  sparkapp:
    image: ghcr.io/miroslavis/sparkapp:1.4
    environment:
      - MASTER_URL=spark://sparkmaster:7077
      - SPARK_JARS=/app/lib
      - SPARK_PYFILES=/app/lib
      - SPARK_APP=/app/main.py
      - WEBUI_PORT=4040
    ports:
      - "4040:4040"
      - "5000:5000"
    working_dir: /app
#    entrypoint: tail -F /dev/null
#
    volumes:
#      - ..\docker-app\app:/app    # For Windows systems
      - ../docker-app/app:/app   # For UNIX systems
